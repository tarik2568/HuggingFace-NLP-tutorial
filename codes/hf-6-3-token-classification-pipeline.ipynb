{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import pipeline\ntoken_classifier = pipeline(\"token-classification\")\ntoken_classifier(\"My name is Tamiti and I am living at Khulna.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:56:38.243465Z","iopub.execute_input":"2023-08-07T03:56:38.243869Z","iopub.status.idle":"2023-08-07T03:56:46.417857Z","shell.execute_reply.started":"2023-08-07T03:56:38.243838Z","shell.execute_reply":"2023-08-07T03:56:46.416725Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[{'entity': 'I-PER',\n  'score': 0.99655175,\n  'index': 4,\n  'word': 'Tam',\n  'start': 11,\n  'end': 14},\n {'entity': 'I-PER',\n  'score': 0.9944008,\n  'index': 5,\n  'word': '##iti',\n  'start': 14,\n  'end': 17},\n {'entity': 'I-LOC',\n  'score': 0.99924374,\n  'index': 11,\n  'word': 'K',\n  'start': 37,\n  'end': 38},\n {'entity': 'I-LOC',\n  'score': 0.99848133,\n  'index': 12,\n  'word': '##hul',\n  'start': 38,\n  'end': 41},\n {'entity': 'I-LOC',\n  'score': 0.99706787,\n  'index': 13,\n  'word': '##na',\n  'start': 41,\n  'end': 43}]"},"metadata":{}}]},{"cell_type":"code","source":"token_classifier = pipeline(\"token-classification\", aggregation_strategy = \"simple\")\ntoken_classifier(\"My name is Tamiti and I live in Khulna.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:56:46.419818Z","iopub.execute_input":"2023-08-07T03:56:46.420147Z","iopub.status.idle":"2023-08-07T03:56:51.347312Z","shell.execute_reply.started":"2023-08-07T03:56:46.420118Z","shell.execute_reply":"2023-08-07T03:56:51.346013Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'entity_group': 'PER',\n  'score': 0.9966186,\n  'word': 'Tamiti',\n  'start': 11,\n  'end': 17},\n {'entity_group': 'LOC',\n  'score': 0.99782854,\n  'word': 'Khulna',\n  'start': 32,\n  'end': 38}]"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification\nmodel_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = AutoModelForTokenClassification.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:56:51.349012Z","iopub.execute_input":"2023-08-07T03:56:51.349981Z","iopub.status.idle":"2023-08-07T03:56:55.130433Z","shell.execute_reply.started":"2023-08-07T03:56:51.349940Z","shell.execute_reply":"2023-08-07T03:56:55.129412Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"example = \"My name is Tamiti and I live in Khulna.\"\ninputs = tokenizer(example, return_tensors= \"pt\")\noutputs = model(**inputs)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:56:55.133733Z","iopub.execute_input":"2023-08-07T03:56:55.134247Z","iopub.status.idle":"2023-08-07T03:56:55.448125Z","shell.execute_reply.started":"2023-08-07T03:56:55.134205Z","shell.execute_reply":"2023-08-07T03:56:55.446867Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(inputs[\"input_ids\"].shape)\nprint(outputs.logits.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:56:55.449806Z","iopub.execute_input":"2023-08-07T03:56:55.450551Z","iopub.status.idle":"2023-08-07T03:56:55.457271Z","shell.execute_reply.started":"2023-08-07T03:56:55.450507Z","shell.execute_reply":"2023-08-07T03:56:55.456131Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"torch.Size([1, 15])\ntorch.Size([1, 15, 9])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nprobabilities = torch.nn.functional.softmax(outputs.logits, dim = -1)\npredictions = probabilities.argmax(dim=-1)[0].tolist()\nprint(predictions)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:56:55.458763Z","iopub.execute_input":"2023-08-07T03:56:55.459192Z","iopub.status.idle":"2023-08-07T03:56:55.475077Z","shell.execute_reply.started":"2023-08-07T03:56:55.459153Z","shell.execute_reply":"2023-08-07T03:56:55.473909Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 8, 8, 8, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\nprobabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].tolist()\npredictions = outputs.logits.argmax(dim=-1)[0].tolist()\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:56:55.476507Z","iopub.execute_input":"2023-08-07T03:56:55.476811Z","iopub.status.idle":"2023-08-07T03:56:55.489133Z","shell.execute_reply.started":"2023-08-07T03:56:55.476784Z","shell.execute_reply":"2023-08-07T03:56:55.488110Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 8, 8, 8, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.id2label","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:56:55.491196Z","iopub.execute_input":"2023-08-07T03:56:55.492891Z","iopub.status.idle":"2023-08-07T03:56:55.503149Z","shell.execute_reply.started":"2023-08-07T03:56:55.492858Z","shell.execute_reply":"2023-08-07T03:56:55.501928Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{0: 'O',\n 1: 'B-MISC',\n 2: 'I-MISC',\n 3: 'B-PER',\n 4: 'I-PER',\n 5: 'B-ORG',\n 6: 'I-ORG',\n 7: 'B-LOC',\n 8: 'I-LOC'}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification\n\nmodel_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint,return_offset_mapping = True)\nmodel = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n\nexample = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\ninputs = tokenizer(example, return_tensors=\"pt\")\noutputs = model(**inputs)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:59:16.934992Z","iopub.execute_input":"2023-08-07T03:59:16.935395Z","iopub.status.idle":"2023-08-07T03:59:20.984721Z","shell.execute_reply.started":"2023-08-07T03:59:16.935362Z","shell.execute_reply":"2023-08-07T03:59:20.983682Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(inputs[\"input_ids\"].shape)\nprint(outputs.logits.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:57:00.037119Z","iopub.execute_input":"2023-08-07T03:57:00.037565Z","iopub.status.idle":"2023-08-07T03:57:00.043517Z","shell.execute_reply.started":"2023-08-07T03:57:00.037533Z","shell.execute_reply":"2023-08-07T03:57:00.042316Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"torch.Size([1, 19])\ntorch.Size([1, 19, 9])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\nprobabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].tolist()\npredictions = outputs.logits.argmax(dim=-1)[0].tolist()\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:57:00.045073Z","iopub.execute_input":"2023-08-07T03:57:00.045488Z","iopub.status.idle":"2023-08-07T03:57:00.058838Z","shell.execute_reply.started":"2023-08-07T03:57:00.045449Z","shell.execute_reply":"2023-08-07T03:57:00.057543Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.id2label","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:57:00.060219Z","iopub.execute_input":"2023-08-07T03:57:00.060676Z","iopub.status.idle":"2023-08-07T03:57:00.072775Z","shell.execute_reply.started":"2023-08-07T03:57:00.060636Z","shell.execute_reply":"2023-08-07T03:57:00.071565Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{0: 'O',\n 1: 'B-MISC',\n 2: 'I-MISC',\n 3: 'B-PER',\n 4: 'I-PER',\n 5: 'B-ORG',\n 6: 'I-ORG',\n 7: 'B-LOC',\n 8: 'I-LOC'}"},"metadata":{}}]},{"cell_type":"code","source":"results = []\ntokens = inputs.tokens()\n\nfor idx, pred in enumerate(predictions):\n    label = model.config.id2label[pred]\n    if label != \"O\":\n        results.append(\n            {\"entity\": label, \"score\": probabilities[idx][pred], \"word\": tokens[idx]}\n        )\n\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:57:00.074604Z","iopub.execute_input":"2023-08-07T03:57:00.074932Z","iopub.status.idle":"2023-08-07T03:57:00.085387Z","shell.execute_reply.started":"2023-08-07T03:57:00.074903Z","shell.execute_reply":"2023-08-07T03:57:00.084204Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[{'entity': 'I-PER', 'score': 0.9993828535079956, 'word': 'S'}, {'entity': 'I-PER', 'score': 0.9981548190116882, 'word': '##yl'}, {'entity': 'I-PER', 'score': 0.995907187461853, 'word': '##va'}, {'entity': 'I-PER', 'score': 0.9992327690124512, 'word': '##in'}, {'entity': 'I-ORG', 'score': 0.9738932251930237, 'word': 'Hu'}, {'entity': 'I-ORG', 'score': 0.9761149883270264, 'word': '##gging'}, {'entity': 'I-ORG', 'score': 0.9887974858283997, 'word': 'Face'}, {'entity': 'I-LOC', 'score': 0.99321049451828, 'word': 'Brooklyn'}]\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\ninputs_with_offsets[\"offset_mapping\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:57:00.086849Z","iopub.execute_input":"2023-08-07T03:57:00.087592Z","iopub.status.idle":"2023-08-07T03:57:00.103300Z","shell.execute_reply.started":"2023-08-07T03:57:00.087540Z","shell.execute_reply":"2023-08-07T03:57:00.102222Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[(0, 0),\n (0, 2),\n (3, 7),\n (8, 10),\n (11, 12),\n (12, 14),\n (14, 16),\n (16, 18),\n (19, 22),\n (23, 24),\n (25, 29),\n (30, 32),\n (33, 35),\n (35, 40),\n (41, 45),\n (46, 48),\n (49, 57),\n (57, 58),\n (0, 0)]"},"metadata":{}}]},{"cell_type":"code","source":"example[12:14]","metadata":{"execution":{"iopub.status.busy":"2023-08-07T03:57:57.331705Z","iopub.execute_input":"2023-08-07T03:57:57.332118Z","iopub.status.idle":"2023-08-07T03:57:57.339378Z","shell.execute_reply.started":"2023-08-07T03:57:57.332085Z","shell.execute_reply":"2023-08-07T03:57:57.338242Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'yl'"},"metadata":{}}]},{"cell_type":"code","source":"results = []\ninputs = tokenizer(example, return_tensors = \"pt\")\ninputs_with_offsets = tokenizer(example,  return_tensors= \"pt\", return_offsets_mapping = True)\ntokens = inputs_with_offsets.tokens()\noffsets = inputs_with_offsets[\"offset_mapping\"]\noutputs = model(**inputs)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-07T04:12:14.848509Z","iopub.execute_input":"2023-08-07T04:12:14.849016Z","iopub.status.idle":"2023-08-07T04:12:15.191442Z","shell.execute_reply.started":"2023-08-07T04:12:14.848977Z","shell.execute_reply":"2023-08-07T04:12:15.190103Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import torch\nprobabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].tolist()\npredictions = outputs.logits.argmax(dim=-1)[0].tolist()\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T04:12:02.974137Z","iopub.execute_input":"2023-08-07T04:12:02.974691Z","iopub.status.idle":"2023-08-07T04:12:02.983681Z","shell.execute_reply.started":"2023-08-07T04:12:02.974650Z","shell.execute_reply":"2023-08-07T04:12:02.982240Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"offsets","metadata":{"execution":{"iopub.status.busy":"2023-08-07T04:35:29.022178Z","iopub.execute_input":"2023-08-07T04:35:29.023186Z","iopub.status.idle":"2023-08-07T04:35:29.031109Z","shell.execute_reply.started":"2023-08-07T04:35:29.023138Z","shell.execute_reply":"2023-08-07T04:35:29.029995Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 0,  0],\n         [ 0,  2],\n         [ 3,  7],\n         [ 8, 10],\n         [11, 12],\n         [12, 14],\n         [14, 16],\n         [16, 18],\n         [19, 22],\n         [23, 24],\n         [25, 29],\n         [30, 32],\n         [33, 35],\n         [35, 40],\n         [41, 45],\n         [46, 48],\n         [49, 57],\n         [57, 58],\n         [ 0,  0]]])"},"metadata":{}}]},{"cell_type":"code","source":"for idx, pred in enumerate(predictions):\n    label = model.config.id2label[pred]\n    if label != \"0\":\n        start,end = offsets[:.idx]","metadata":{"execution":{"iopub.status.busy":"2023-08-07T04:40:19.678584Z","iopub.execute_input":"2023-08-07T04:40:19.679030Z","iopub.status.idle":"2023-08-07T04:40:19.689600Z","shell.execute_reply.started":"2023-08-07T04:40:19.678992Z","shell.execute_reply":"2023-08-07T04:40:19.688322Z"},"trusted":true},"execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[91m╭──────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n\u001b[91m│\u001b[0m         start,end = offsets\u001b[1m[\u001b[0m:.idx\u001b[1m]\u001b[0m                                                               \u001b[91m│\u001b[0m\n\u001b[91m│\u001b[0m                              \u001b[1;91m▲\u001b[0m                                                                   \u001b[91m│\u001b[0m\n\u001b[91m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mSyntaxError: \u001b[0minvalid syntax\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>         start,end = offsets<span style=\"font-weight: bold\">[</span>:.idx<span style=\"font-weight: bold\">]</span>                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                              <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">▲</span>                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">SyntaxError: </span>invalid syntax\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"results = []\ninputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\ntokens = inputs_with_offsets.tokens()\noffsets = inputs_with_offsets[\"offset_mapping\"]\n\nfor idx, pred in enumerate(predictions):\n    label = model.config.id2label[pred]\n    if label != \"O\":\n        start, end = offsets[idx]\n        results.append(\n            {\n                \"entity\": label,\n                \"score\": probabilities[idx][pred],\n                \"word\": tokens[idx],\n                \"start\": start,\n                \"end\": end,\n            }\n        )\n\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T05:02:13.965584Z","iopub.execute_input":"2023-08-07T05:02:13.966411Z","iopub.status.idle":"2023-08-07T05:02:13.983280Z","shell.execute_reply.started":"2023-08-07T05:02:13.966340Z","shell.execute_reply":"2023-08-07T05:02:13.981571Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"[{'entity': 'I-PER', 'score': 0.9993828535079956, 'word': 'S', 'start': 11, 'end': 12}, {'entity': 'I-PER', 'score': 0.9981548190116882, 'word': '##yl', 'start': 12, 'end': 14}, {'entity': 'I-PER', 'score': 0.995907187461853, 'word': '##va', 'start': 14, 'end': 16}, {'entity': 'I-PER', 'score': 0.9992327690124512, 'word': '##in', 'start': 16, 'end': 18}, {'entity': 'I-ORG', 'score': 0.9738932251930237, 'word': 'Hu', 'start': 33, 'end': 35}, {'entity': 'I-ORG', 'score': 0.9761149883270264, 'word': '##gging', 'start': 35, 'end': 40}, {'entity': 'I-ORG', 'score': 0.9887974858283997, 'word': 'Face', 'start': 41, 'end': 45}, {'entity': 'I-LOC', 'score': 0.99321049451828, 'word': 'Brooklyn', 'start': 49, 'end': 57}]\n","output_type":"stream"}]},{"cell_type":"code","source":"offsets","metadata":{"execution":{"iopub.status.busy":"2023-08-07T05:02:38.744906Z","iopub.execute_input":"2023-08-07T05:02:38.745437Z","iopub.status.idle":"2023-08-07T05:02:38.757034Z","shell.execute_reply.started":"2023-08-07T05:02:38.745394Z","shell.execute_reply":"2023-08-07T05:02:38.755451Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"[(0, 0),\n (0, 2),\n (3, 7),\n (8, 10),\n (11, 12),\n (12, 14),\n (14, 16),\n (16, 18),\n (19, 22),\n (23, 24),\n (25, 29),\n (30, 32),\n (33, 35),\n (35, 40),\n (41, 45),\n (46, 48),\n (49, 57),\n (57, 58),\n (0, 0)]"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\nresults = []\ninputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\ntokens = inputs_with_offsets.tokens()\noffsets = inputs_with_offsets[\"offset_mapping\"]\n\nidx = 0\nwhile idx < len(predictions):\n    pred = predictions[idx]\n    label = model.config.id2label[pred]\n    if label != \"O\":\n        # Remove the B- or I-\n        label = label[2:]\n        start, _ = offsets[idx]\n\n        # Grab all the tokens labeled with I-label\n        all_scores = []\n        while (\n            idx < len(predictions)\n            and model.config.id2label[predictions[idx]] == f\"I-{label}\"\n        ):\n            all_scores.append(probabilities[idx][pred])\n            _, end = offsets[idx]\n            idx += 1\n\n        # The score is the mean of all the scores of the tokens in that grouped entity\n        score = np.mean(all_scores).item()\n        word = example[start:end]\n        results.append(\n            {\n                \"entity_group\": label,\n                \"score\": score,\n                \"word\": word,\n                \"start\": start,\n                \"end\": end,\n            }\n        )\n    idx += 1\n\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T05:09:38.057431Z","iopub.execute_input":"2023-08-07T05:09:38.058043Z","iopub.status.idle":"2023-08-07T05:09:38.075222Z","shell.execute_reply.started":"2023-08-07T05:09:38.057999Z","shell.execute_reply":"2023-08-07T05:09:38.073602Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"[{'entity_group': 'PER', 'score': 0.998169407248497, 'word': 'Sylvain', 'start': 11, 'end': 18}, {'entity_group': 'ORG', 'score': 0.9796018997828165, 'word': 'Hugging Face', 'start': 33, 'end': 45}, {'entity_group': 'LOC', 'score': 0.99321049451828, 'word': 'Brooklyn', 'start': 49, 'end': 57}]\n","output_type":"stream"}]}]}